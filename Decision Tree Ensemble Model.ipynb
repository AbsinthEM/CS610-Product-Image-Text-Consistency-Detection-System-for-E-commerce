{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOi8W1Pf8BIlkgQ4fGNeVoD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0vYO59j-oY6","executionInfo":{"status":"ok","timestamp":1741424375957,"user_tz":-480,"elapsed":27590,"user":{"displayName":"柳子桓","userId":"13259233147650512347"}},"outputId":"7f029b6a-c9bc-4233-8c79-69c871ebe6cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxEI4vYL8ICe"},"outputs":[],"source":["import pandas as pd\n","\n","# Load splited data\n","train_path = \"/content/drive/MyDrive/GitHub_Repos/CS610-Product-Image-Text-Consistency-Detection-System-for-E-commerce/amazon_meta_data/split_data/train_data.parquet\"\n","val_path = '/content/drive/MyDrive/GitHub_Repos/CS610-Product-Image-Text-Consistency-Detection-System-for-E-commerce/amazon_meta_data/split_data/val_data.parquet'\n","test_path = '/content/drive/MyDrive/GitHub_Repos/CS610-Product-Image-Text-Consistency-Detection-System-for-E-commerce/amazon_meta_data/split_data/test_data.parquet'\n","\n","train_df = pd.read_parquet(train_path)\n","val_df = pd.read_parquet(val_path)\n","test_df = pd.read_parquet(test_path)"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from skimage.feature import hog\n","from skimage import io, color, transform\n","from sklearn.decomposition import PCA\n","import cv2\n","from tqdm import tqdm\n","import joblib\n","import os\n","from concurrent.futures import ProcessPoolExecutor, as_completed\n","import multiprocessing\n","\n","def extract_image_features(image_path):\n","    \"\"\"Extract HOG and color features from a single image\"\"\"\n","    try:\n","        # Read the image\n","        img = cv2.imread(image_path)\n","        if img is None:\n","            return None\n","\n","        # Convert to RGB (OpenCV uses BGR by default)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        # 1. HOG features\n","        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","        hog_features = hog(\n","            img_gray,\n","            orientations=9,\n","            pixels_per_cell=(8, 8),\n","            cells_per_block=(2, 2),\n","            visualize=False\n","        )\n","\n","        # 2. Color Histogram\n","        color_features = []\n","        for i in range(3):  # RGB channels\n","            hist = cv2.calcHist([img], [i], None, [32], [0, 256])\n","            color_features.extend(hist.flatten())\n","\n","        # Combine all image features\n","        return np.concatenate([hog_features, np.array(color_features)])\n","\n","    except Exception as e:\n","        print(f\"Error processing image {image_path}: {e}\")\n","        return None\n","\n","\n","def preprocess_for_tree_ensemble(train_df, val_df, test_df,\n","                                 text_column='text_for_tfidf',\n","                                 image_column='processed_image_path',\n","                                 output_dir='tree_ensemble_features',\n","                                 n_jobs=-1):\n","    \"\"\"\n","    Extract and prepare features for decision tree ensemble model.\n","\n","    Parameters:\n","    train_df, val_df, test_df: Splitted datasets\n","    text_column: Name of the column containing preprocessed text\n","    image_column: Name of the column containing image paths\n","    output_dir: Directory to save extracted features\n","    n_jobs: Number of jobs for parallel processing\n","\n","    Returns:\n","    dict: Dictionary containing all features and vectorizers\n","    \"\"\"\n","    if n_jobs == -1:\n","        n_jobs = multiprocessing.cpu_count()\n","\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    print(\"Preparing features for decision tree ensemble model...\")\n","\n","    # ==== 1. Text Feature Extraction ====\n","    print(\"\\n1. Text Feature Extraction - TF-IDF\")\n","\n","    # Create TF-IDF vectorizer\n","    tfidf_vectorizer = TfidfVectorizer(\n","        max_features=5000,  # Limit the number of features to avoid dimensional explosion\n","        min_df=5,           # Appear in at least 5 documents\n","        max_df=0.85,        # Appear in no more than 85% of documents\n","        ngram_range=(1, 2)  # Use 1-gram and 2-gram\n","    )\n","\n","    # Fit and transform on the training set\n","    print(\"  Fitting TF-IDF vectorizer...\")\n","    X_text_train = tfidf_vectorizer.fit_transform(train_df[text_column])\n","\n","    # Transform validation and test sets\n","    X_text_val = tfidf_vectorizer.transform(val_df[text_column])\n","    X_text_test = tfidf_vectorizer.transform(test_df[text_column])\n","\n","    print(f\"  Text feature shape: {X_text_train.shape[1]} dimensions\")\n","\n","    # Save the vectorizer\n","    joblib.dump(tfidf_vectorizer, os.path.join(output_dir, 'tfidf_vectorizer.pkl'))\n","\n","    # ==== 2. Image Feature Extraction ====\n","    print(\"\\n2. Image Feature Extraction - HOG and Color Histogram\")\n","\n","    # Parallel processing of image feature extraction\n","    def process_dataset_images(df):\n","        features = []\n","        valid_indices = []\n","\n","        image_paths = df[image_column].tolist()\n","\n","        with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n","            futures = {executor.submit(extract_image_features, path): i\n","                      for i, path in enumerate(image_paths)}\n","\n","            with tqdm(total=len(futures), desc=\"Extracting Image Features\") as pbar:\n","                for future in as_completed(futures):\n","                    idx = futures[future]\n","                    result = future.result()\n","                    if result is not None:\n","                        features.append(result)\n","                        valid_indices.append(idx)\n","                    pbar.update(1)\n","\n","        # Convert to numpy array\n","        if features:\n","            features_array = np.vstack(features)\n","            return features_array, valid_indices\n","        else:\n","            return np.array([]), []\n","\n","    # Extract training set image features\n","    print(\"  Extracting training set image features...\")\n","    X_img_train, train_valid_indices = process_dataset_images(train_df)\n","\n","    # If valid image features exist\n","    if len(X_img_train) > 0:\n","        # Keep only valid image samples\n","        train_df_valid = train_df.iloc[train_valid_indices].reset_index(drop=True)\n","        X_text_train_valid = X_text_train[train_valid_indices]\n","\n","        # Apply PCA on image features\n","        print(\"  Applying PCA on image features...\")\n","        pca = PCA(n_components=min(300, X_img_train.shape[1], X_img_train.shape[0]),\n","                 random_state=42)\n","        X_img_train_pca = pca.fit_transform(X_img_train)\n","        joblib.dump(pca, os.path.join(output_dir, 'image_pca.pkl'))\n","\n","        # Extract image features for validation and test sets\n","        print(\"  Extracting validation set image features...\")\n","        X_img_val, val_valid_indices = process_dataset_images(val_df)\n","        if len(X_img_val) > 0:\n","            X_img_val_pca = pca.transform(X_img_val)\n","            val_df_valid = val_df.iloc[val_valid_indices].reset_index(drop=True)\n","            X_text_val_valid = X_text_val[val_valid_indices]\n","        else:\n","            X_img_val_pca = np.array([])\n","            val_df_valid = pd.DataFrame()\n","            X_text_val_valid = None\n","\n","        print(\"  Extracting test set image features...\")\n","        X_img_test, test_valid_indices = process_dataset_images(test_df)\n","        if len(X_img_test) > 0:\n","            X_img_test_pca = pca.transform(X_img_test)\n","            test_df_valid = test_df.iloc[test_valid_indices].reset_index(drop=True)\n","            X_text_test_valid = X_text_test[test_valid_indices]\n","        else:\n","            X_img_test_pca = np.array([])\n","            test_df_valid = pd.DataFrame()\n","            X_text_test_valid = None\n","\n","        # ==== 3. Feature Fusion ====\n","        print(\"\\n3. Fusion of Text and Image Features\")\n","\n","        # Convert sparse matrix to dense matrix\n","        X_text_train_dense = X_text_train_valid.toarray()\n","\n","        # Fusion of features (simple concatenation)\n","        X_train_combined = np.hstack([X_text_train_dense, X_img_train_pca])\n","\n","        if len(X_img_val) > 0:\n","            X_text_val_dense = X_text_val_valid.toarray()\n","            X_val_combined = np.hstack([X_text_val_dense, X_img_val_pca])\n","        else:\n","            X_val_combined = np.array([])\n","\n","        if len(X_img_test) > 0:\n","            X_text_test_dense = X_text_test_valid.toarray()\n","            X_test_combined = np.hstack([X_text_test_dense, X_img_test_pca])\n","        else:\n","            X_test_combined = np.array([])\n","\n","        print(f\"  Final feature dimensions: {X_train_combined.shape[1]}\")\n","\n","        # Get labels\n","        y_train = train_df_valid['is_match'].values\n","\n","        if not val_df_valid.empty:\n","            y_val = val_df_valid['is_match'].values\n","        else:\n","            y_val = np.array([])\n","\n","        if not test_df_valid.empty:\n","            y_test = test_df_valid['is_match'].values\n","        else:\n","            y_test = np.array([])\n","\n","        # Save features and labels\n","        print(\"\\nSaving processed features...\")\n","        np.save(os.path.join(output_dir, 'X_train.npy'), X_train_combined)\n","        np.save(os.path.join(output_dir, 'y_train.npy'), y_train)\n","\n","        if len(X_val_combined) > 0:\n","            np.save(os.path.join(output_dir, 'X_val.npy'), X_val_combined)\n","            np.save(os.path.join(output_dir, 'y_val.npy'), y_val)\n","\n","        if len(X_test_combined) > 0:\n","            np.save(os.path.join(output_dir, 'X_test.npy'), X_test_combined)\n","            np.save(os.path.join(output_dir, 'y_test.npy'), y_test)\n","\n","        # Save valid sample information\n","        train_df_valid.to_csv(os.path.join(output_dir, 'train_df_valid.csv'), index=False)\n","        if not val_df_valid.empty:\n","            val_df_valid.to_csv(os.path.join(output_dir, 'val_df_valid.csv'), index=False)\n","        if not test_df_valid.empty:\n","            test_df_valid.to_csv(os.path.join(output_dir, 'test_df_valid.csv'), index=False)\n","\n","        print(\"\\nDecision tree ensemble model feature preparation completed!\")\n","\n","        return {\n","            'X_train': X_train_combined,\n","            'y_train': y_train,\n","            'X_val': X_val_combined if len(X_val_combined) > 0 else None,\n","            'y_val': y_val if len(y_val) > 0 else None,\n","            'X_test': X_test_combined if len(X_test_combined) > 0 else None,\n","            'y_test': y_test if len(y_test) > 0 else None,\n","            'train_df': train_df_valid,\n","            'val_df': val_df_valid if not val_df_valid.empty else None,\n","            'test_df': test_df_valid if not test_df_valid.empty else None,\n","            'tfidf_vectorizer': tfidf_vectorizer,\n","            'pca': pca\n","        }\n","    else:\n","        print(\"Error: Unable to extract valid image features from the training set\")\n","        return None\n","\n","\n","tree_ensemble_features = preprocess_for_tree_ensemble(train_df, val_df, test_df,\n","                                       output_dir='/content/drive/MyDrive/GitHub_Repos/CS610-Product-Image-Text-Consistency-Detection-System-for-E-commerce/amazon_meta_data/tree_ensemble_features')"],"metadata":{"id":"fheI1auy9ukL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import joblib\n","import os\n","\n","def load_tree_ensemble_features(output_dir):\n","    \"\"\"\n","    Load previously saved feature files from the specified directory and reconstruct the tree_ensemble_features dictionary.\n","\n","    Parameters:\n","    output_dir: Directory where the feature files were previously saved.\n","\n","    Returns:\n","    dict: A dictionary containing all the features and vectorizers.\n","    \"\"\"\n","    print(f\"Loading feature files from {output_dir}...\")\n","\n","    # Create result dictionary\n","    tree_ensemble_features = {}\n","\n","    # 1. Load the TF-IDF vectorizer\n","    tfidf_path = os.path.join(output_dir, 'tfidf_vectorizer.pkl')\n","    if os.path.exists(tfidf_path):\n","        print(\"Loading TF-IDF vectorizer...\")\n","        tfidf_vectorizer = joblib.load(tfidf_path)\n","        tree_ensemble_features['tfidf_vectorizer'] = tfidf_vectorizer\n","    else:\n","        print(f\"Warning: TF-IDF vectorizer file not found at {tfidf_path}\")\n","\n","    # 2. Load the image PCA model\n","    pca_path = os.path.join(output_dir, 'image_pca.pkl')\n","    if os.path.exists(pca_path):\n","        print(\"Loading image PCA model...\")\n","        pca = joblib.load(pca_path)\n","        tree_ensemble_features['pca'] = pca\n","    else:\n","        print(f\"Warning: PCA model file not found at {pca_path}\")\n","\n","    # 3. Load training features and labels\n","    X_train_path = os.path.join(output_dir, 'X_train.npy')\n","    y_train_path = os.path.join(output_dir, 'y_train.npy')\n","\n","    if os.path.exists(X_train_path) and os.path.exists(y_train_path):\n","        print(\"Loading training features and labels...\")\n","        tree_ensemble_features['X_train'] = np.load(X_train_path)\n","        tree_ensemble_features['y_train'] = np.load(y_train_path)\n","        print(f\"  Training feature shape: {tree_ensemble_features['X_train'].shape}\")\n","    else:\n","        print(f\"Warning: Training features or labels file not found\")\n","\n","    # 4. Load validation features and labels\n","    X_val_path = os.path.join(output_dir, 'X_val.npy')\n","    y_val_path = os.path.join(output_dir, 'y_val.npy')\n","\n","    if os.path.exists(X_val_path) and os.path.exists(y_val_path):\n","        print(\"Loading validation features and labels...\")\n","        tree_ensemble_features['X_val'] = np.load(X_val_path)\n","        tree_ensemble_features['y_val'] = np.load(y_val_path)\n","        print(f\"  Validation feature shape: {tree_ensemble_features['X_val'].shape}\")\n","    else:\n","        print(f\"Note: Validation features or labels file not found, setting as None\")\n","        tree_ensemble_features['X_val'] = None\n","        tree_ensemble_features['y_val'] = None\n","\n","    # 5. Load test features and labels\n","    X_test_path = os.path.join(output_dir, 'X_test.npy')\n","    y_test_path = os.path.join(output_dir, 'y_test.npy')\n","\n","    if os.path.exists(X_test_path) and os.path.exists(y_test_path):\n","        print(\"Loading test features and labels...\")\n","        tree_ensemble_features['X_test'] = np.load(X_test_path)\n","        tree_ensemble_features['y_test'] = np.load(y_test_path)\n","        print(f\"  Test feature shape: {tree_ensemble_features['X_test'].shape}\")\n","    else:\n","        print(f\"Note: Test features or labels file not found, setting as None\")\n","        tree_ensemble_features['X_test'] = None\n","        tree_ensemble_features['y_test'] = None\n","\n","    # 6. Load dataframes\n","    train_df_path = os.path.join(output_dir, 'train_df_valid.csv')\n","    val_df_path = os.path.join(output_dir, 'val_df_valid.csv')\n","    test_df_path = os.path.join(output_dir, 'test_df_valid.csv')\n","\n","    if os.path.exists(train_df_path):\n","        print(\"Loading training dataframe...\")\n","        tree_ensemble_features['train_df'] = pd.read_csv(train_df_path)\n","    else:\n","        print(f\"Warning: Training dataframe file not found at {train_df_path}\")\n","        tree_ensemble_features['train_df'] = None\n","\n","    if os.path.exists(val_df_path):\n","        print(\"Loading validation dataframe...\")\n","        tree_ensemble_features['val_df'] = pd.read_csv(val_df_path)\n","    else:\n","        print(f\"Note: Validation dataframe file not found, setting as None\")\n","        tree_ensemble_features['val_df'] = None\n","\n","    if os.path.exists(test_df_path):\n","        print(\"Loading test dataframe...\")\n","        tree_ensemble_features['test_df'] = pd.read_csv(test_df_path)\n","    else:\n","        print(f\"Note: Test dataframe file not found, setting as None\")\n","        tree_ensemble_features['test_df'] = None\n","\n","    print(\"\\nLoading complete!\")\n","    return tree_ensemble_features\n","\n","tree_ensemble_data = load_tree_ensemble_features(output_dir='/content/drive/MyDrive/GitHub_Repos/CS610-Product-Image-Text-Consistency-Detection-System-for-E-commerce/amazon_meta_data/tree_ensemble_features')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGQULiDL82qI","executionInfo":{"status":"ok","timestamp":1741424442521,"user_tz":-480,"elapsed":34964,"user":{"displayName":"柳子桓","userId":"13259233147650512347"}},"outputId":"e4a6c958-42b4-45a3-9211-3851eff09831"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading feature files from /content/drive/MyDrive/amazon_meta_data/tree_ensemble_features...\n","Loading TF-IDF vectorizer...\n","Loading image PCA model...\n","Loading training features and labels...\n","  Training feature shape: (35923, 5300)\n","Loading validation features and labels...\n","  Validation feature shape: (5132, 5300)\n","Loading test features and labels...\n","  Test feature shape: (10265, 5300)\n","Loading training dataframe...\n","Loading validation dataframe...\n","Loading test dataframe...\n","\n","Loading complete!\n"]}]}]}